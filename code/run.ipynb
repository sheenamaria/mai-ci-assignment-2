{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the project directory to the Python path\n",
    "project_dir = Path.cwd().parent\n",
    "sys.path.append(str(project_dir))\n",
    "\n",
    "from data import Data\n",
    "from cnn import CNN\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset\n",
    "\n",
    "- Preprocess\n",
    "- Build splits (Training/Validation/Testing):\n",
    "  - 80/20/00 -> For the hyperparameter search\n",
    "  - 80/10/10\n",
    "  - 40/20/40\n",
    "  - 10/10/80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset0 = Data('caltech101_silhouettes_28.mat', train_split=80, val_split=20, test_split=0)\n",
    "dataset1 = Data('caltech101_silhouettes_28.mat', train_split=80, val_split=10, test_split=10)\n",
    "dataset2 = Data('caltech101_silhouettes_28.mat', train_split=40, val_split=20, test_split=40)\n",
    "dataset3 = Data('caltech101_silhouettes_28.mat', train_split=10, val_split=10, test_split=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Search\n",
    "Previous to the study of CNN configurations\n",
    "\n",
    "- OL Activation function\n",
    "- CFL Cost Function\n",
    "- Dense Layer Size\n",
    "- Learning rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: OA=softmax, CF=categorical_crossentropy, DLS=64, LR=0.01\n",
      "Training with parameters: OA=softmax, CF=categorical_crossentropy, DLS=64, LR=0.1\n",
      "Training with parameters: OA=softmax, CF=categorical_crossentropy, DLS=128, LR=0.01\n",
      "Training with parameters: OA=softmax, CF=categorical_crossentropy, DLS=128, LR=0.1\n",
      "Training with parameters: OA=softmax, CF=mean_squared_error, DLS=64, LR=0.01\n",
      "Training with parameters: OA=softmax, CF=mean_squared_error, DLS=64, LR=0.1\n",
      "Training with parameters: OA=softmax, CF=mean_squared_error, DLS=128, LR=0.01\n",
      "Training with parameters: OA=softmax, CF=mean_squared_error, DLS=128, LR=0.1\n",
      "Training with parameters: OA=sigmoid, CF=categorical_crossentropy, DLS=64, LR=0.01\n",
      "Training with parameters: OA=sigmoid, CF=categorical_crossentropy, DLS=64, LR=0.1\n",
      "Training with parameters: OA=sigmoid, CF=categorical_crossentropy, DLS=128, LR=0.01\n",
      "Training with parameters: OA=sigmoid, CF=categorical_crossentropy, DLS=128, LR=0.1\n",
      "Training with parameters: OA=sigmoid, CF=mean_squared_error, DLS=64, LR=0.01\n",
      "Training with parameters: OA=sigmoid, CF=mean_squared_error, DLS=64, LR=0.1\n",
      "Training with parameters: OA=sigmoid, CF=mean_squared_error, DLS=128, LR=0.01\n",
      "Training with parameters: OA=sigmoid, CF=mean_squared_error, DLS=128, LR=0.1\n",
      "Params: ('sigmoid', 'categorical_crossentropy', 64, 0.01), Validation Accuracy: 0.5383\n",
      "Params: ('softmax', 'categorical_crossentropy', 64, 0.01), Validation Accuracy: 0.5222\n",
      "Params: ('sigmoid', 'categorical_crossentropy', 128, 0.01), Validation Accuracy: 0.5190\n",
      "Params: ('softmax', 'categorical_crossentropy', 128, 0.01), Validation Accuracy: 0.5179\n",
      "Params: ('softmax', 'mean_squared_error', 64, 0.01), Validation Accuracy: 0.3904\n",
      "Params: ('softmax', 'mean_squared_error', 128, 0.01), Validation Accuracy: 0.2330\n",
      "Params: ('sigmoid', 'mean_squared_error', 64, 0.01), Validation Accuracy: 0.1032\n",
      "Params: ('sigmoid', 'mean_squared_error', 64, 0.1), Validation Accuracy: 0.1032\n",
      "Params: ('softmax', 'categorical_crossentropy', 64, 0.1), Validation Accuracy: 0.1032\n",
      "Params: ('sigmoid', 'mean_squared_error', 128, 0.1), Validation Accuracy: 0.0997\n",
      "Params: ('softmax', 'categorical_crossentropy', 128, 0.1), Validation Accuracy: 0.0911\n",
      "Params: ('sigmoid', 'categorical_crossentropy', 64, 0.1), Validation Accuracy: 0.0836\n",
      "Params: ('sigmoid', 'categorical_crossentropy', 128, 0.1), Validation Accuracy: 0.0836\n",
      "Params: ('softmax', 'mean_squared_error', 128, 0.1), Validation Accuracy: 0.0231\n",
      "Params: ('softmax', 'mean_squared_error', 64, 0.1), Validation Accuracy: 0.0104\n",
      "Params: ('sigmoid', 'mean_squared_error', 128, 0.01), Validation Accuracy: 0.0075\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import traceback\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "output_activations = ['softmax', 'sigmoid']\n",
    "cost_functions = ['categorical_crossentropy', 'mean_squared_error']\n",
    "learning_rates = [0.01, 0.1]\n",
    "dense_layer_sizes = [64, 128]\n",
    "max_epochs = 20\n",
    "\n",
    "def train_model_hyperparmeter_search(params):\n",
    "    try:\n",
    "        oa, cf, dls, lr = params\n",
    "        cnn = CNN(output_layer_activation=oa, filter_sizes=[64, 64], dense_layer_size=dls, hidden_layer_activation='tanh')\n",
    "        \n",
    "        print(f\"Training with parameters: OA={oa}, CF={cf}, DLS={dls}, LR={lr}\")\n",
    "        \n",
    "        history = cnn.fit(\n",
    "            dataset0,\n",
    "            cost_function=cf,\n",
    "            max_epochs=max_epochs,\n",
    "            learning_rate=lr\n",
    "        )\n",
    "        \n",
    "        val_acc = history.history['val_accuracy'][-1]\n",
    "        return (oa, cf, dls, lr, val_acc, history)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing parameters {params}:\")\n",
    "        print(traceback.format_exc())\n",
    "        return None\n",
    "\n",
    "# Generate all parameter combinations\n",
    "param_combinations = list(itertools.product(\n",
    "    output_activations, \n",
    "    cost_functions, \n",
    "    dense_layer_sizes,\n",
    "    learning_rates\n",
    "))\n",
    "\n",
    "# Use ThreadPoolExecutor to parallelize\n",
    "hyperparameter_search_results = []\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    # Submit all tasks\n",
    "    futures = [executor.submit(train_model_hyperparmeter_search, params) for params in param_combinations]\n",
    "    \n",
    "    # Collect results as they complete\n",
    "    for future in as_completed(futures):\n",
    "        result = future.result()\n",
    "        if result is not None:\n",
    "            hyperparameter_search_results.append(result)\n",
    "\n",
    "# Sort and display results\n",
    "hyperparameter_search_results = sorted(hyperparameter_search_results, key=lambda x: x[-2], reverse=True)\n",
    "for result in hyperparameter_search_results:\n",
    "    print(f\"Params: {result[:-2]}, Validation Accuracy: {result[-2]:.4f}\")\n",
    "\n",
    "best_hyperparameters = hyperparameter_search_results[0][:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the list to a pickle file\n",
    "with open('hyperparameter_search_results.pkl', 'wb') as file:\n",
    "    pickle.dump(hyperparameter_search_results, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Results\n",
    "\n",
    "Loop over configurations:\n",
    "1. Architecture:\n",
    "  - 1 Block: 128 Filter Size\n",
    "  - 3 Blocks: 32, 64 and 128 Filter Sizes\n",
    "2. Activations:\n",
    "  - Sigmoid\n",
    "  - ReLU\n",
    "3. Dataset Splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: FS=[128], NHL=sigmoid, Splits={'train': 80, 'val': 10, 'test': 10}\n",
      "Training with parameters: FS=[128], NHL=relu, Splits={'train': 80, 'val': 10, 'test': 10}\n",
      "Training with parameters: FS=[32, 64, 128], NHL=sigmoid, Splits={'train': 80, 'val': 10, 'test': 10}\n",
      "Training with parameters: FS=[32, 64, 128], NHL=relu, Splits={'train': 80, 'val': 10, 'test': 10}\n",
      "Training with parameters: FS=[128], NHL=sigmoid, Splits={'train': 40, 'val': 20, 'test': 40}\n",
      "Training with parameters: FS=[128], NHL=relu, Splits={'train': 40, 'val': 20, 'test': 40}\n",
      "Training with parameters: FS=[32, 64, 128], NHL=sigmoid, Splits={'train': 40, 'val': 20, 'test': 40}\n",
      "Training with parameters: FS=[32, 64, 128], NHL=relu, Splits={'train': 40, 'val': 20, 'test': 40}\n",
      "Training with parameters: FS=[128], NHL=sigmoid, Splits={'train': 10, 'val': 10, 'test': 80}\n",
      "Training with parameters: FS=[128], NHL=relu, Splits={'train': 10, 'val': 10, 'test': 80}\n",
      "Training with parameters: FS=[32, 64, 128], NHL=sigmoid, Splits={'train': 10, 'val': 10, 'test': 80}\n",
      "Training with parameters: FS=[32, 64, 128], NHL=relu, Splits={'train': 10, 'val': 10, 'test': 80}\n",
      "\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - accuracy: 0.0859 - loss: 4.2987\n",
      "\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.5218 - loss: 4.4227\n",
      "\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.4229 - loss: 6.0439\n",
      "\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.0859 - loss: 4.2260\n",
      "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.0823 - loss: 4.2772\n",
      "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5716 - loss: 4.3730\n",
      "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.4915 - loss: 3.6845\n",
      "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0989 - loss: 4.1902\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5856 - loss: 6.1539\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0896 - loss: 4.2690\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5080 - loss: 3.6379\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0757 - loss: 4.2189   \n",
      "Params: ([128], 'relu', {'train': 80, 'val': 10, 'test': 10}), Validation Accuracy: 0.6455, Testing Accuracy: 0.5922\n",
      "Params: ([128], 'relu', {'train': 40, 'val': 20, 'test': 40}), Validation Accuracy: 0.6048, Testing Accuracy: 0.5641\n",
      "Params: ([32, 64, 128], 'relu', {'train': 80, 'val': 10, 'test': 10}), Validation Accuracy: 0.5571, Testing Accuracy: 0.5323\n",
      "Params: ([128], 'relu', {'train': 10, 'val': 10, 'test': 80}), Validation Accuracy: 0.5216, Testing Accuracy: 0.5214\n",
      "Params: ([32, 64, 128], 'relu', {'train': 40, 'val': 20, 'test': 40}), Validation Accuracy: 0.5731, Testing Accuracy: 0.4952\n",
      "Params: ([32, 64, 128], 'relu', {'train': 10, 'val': 10, 'test': 80}), Validation Accuracy: 0.4813, Testing Accuracy: 0.4342\n",
      "Params: ([32, 64, 128], 'sigmoid', {'train': 40, 'val': 20, 'test': 40}), Validation Accuracy: 0.1135, Testing Accuracy: 0.1015\n",
      "Params: ([128], 'sigmoid', {'train': 80, 'val': 10, 'test': 10}), Validation Accuracy: 0.1019, Testing Accuracy: 0.0956\n",
      "Params: ([128], 'sigmoid', {'train': 10, 'val': 10, 'test': 80}), Validation Accuracy: 0.1037, Testing Accuracy: 0.0923\n",
      "Params: ([32, 64, 128], 'sigmoid', {'train': 10, 'val': 10, 'test': 80}), Validation Accuracy: 0.1009, Testing Accuracy: 0.0923\n",
      "Params: ([128], 'sigmoid', {'train': 40, 'val': 20, 'test': 40}), Validation Accuracy: 0.1114, Testing Accuracy: 0.0856\n",
      "Params: ([32, 64, 128], 'sigmoid', {'train': 80, 'val': 10, 'test': 10}), Validation Accuracy: 0.1019, Testing Accuracy: 0.0829\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import traceback\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "oa = best_hyperparameters[0]\n",
    "cf =  best_hyperparameters[1]\n",
    "dls =  best_hyperparameters[2]\n",
    "lr =  best_hyperparameters[3]\n",
    "\n",
    "datasets = [dataset1, dataset2, dataset3]\n",
    "filter_sizes = [[128], [32, 64, 128]]\n",
    "hidden_activations = ['sigmoid', 'relu']\n",
    "\n",
    "def train_model_configuration_search(params):\n",
    "    try:\n",
    "        dataset, fs, nhl = params\n",
    "        cnn = CNN(output_layer_activation=oa, filter_sizes=fs, dense_layer_size=dls, hidden_layer_activation=nhl)\n",
    "        \n",
    "        splits = dataset.splits\n",
    "        \n",
    "        print(f\"Training with parameters: FS={fs}, NHL={nhl}, Splits={splits}\")\n",
    "        \n",
    "        history = cnn.fit(\n",
    "            dataset,\n",
    "            cost_function=cf,\n",
    "            max_epochs=max_epochs,\n",
    "            learning_rate=lr\n",
    "        )\n",
    "        \n",
    "        val_acc = max(history.history['val_accuracy'])\n",
    "\n",
    "        test_acc = cnn.evaluate(dataset)\n",
    "\n",
    "        return (fs, nhl, splits, val_acc, test_acc[1], history)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing parameters {params} with dataset {splits}:\")\n",
    "        print(traceback.format_exc())\n",
    "        return None\n",
    "\n",
    "# Generate all parameter combinations\n",
    "param_combinations = list(itertools.product(\n",
    "    datasets,\n",
    "    filter_sizes,\n",
    "    hidden_activations\n",
    "))\n",
    "\n",
    "# Use ThreadPoolExecutor to parallelize\n",
    "configuration_search_results = []\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    # Submit all tasks\n",
    "    futures = [executor.submit(train_model_configuration_search, params) for params in param_combinations]\n",
    "    \n",
    "    # Collect results as they complete\n",
    "    for future in as_completed(futures):\n",
    "        result = future.result()\n",
    "        if result is not None:\n",
    "            configuration_search_results.append(result)\n",
    "\n",
    "# Sort and display results\n",
    "configuration_search_results = sorted(configuration_search_results, key=lambda x: x[-2], reverse=True)\n",
    "for result in configuration_search_results:\n",
    "    print(f\"Params: {result[:-3]}, Validation Accuracy: {result[-3]:.4f}, Testing Accuracy: {result[-2]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the list to a pickle file\n",
    "with open('configuration_search_results.pkl', 'wb') as file:\n",
    "    pickle.dump(configuration_search_results, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hyperparameter_search_results.pkl', 'rb') as file:\n",
    "    hyperparameter_search_results = pickle.load(file)\n",
    "\n",
    "with open('configuration_search_results.pkl', 'rb') as file:\n",
    "    configuration_search_results = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plots and tables comparing the configurations.\n",
    "\n",
    "Tables with Validation Accuracies:\n",
    "- Hyperparameter search\n",
    "- Configuration search\n",
    "\n",
    "Plots:\n",
    "- Hyperparameter Heatmaps\n",
    "- Best run Train-Validation accuracy plot (need to save all of them during the search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks\n",
    "\n",
    "1) Description of the runs with the different configurations that you have performed. -> Sheena\n",
    "2) Explain how you have selected the rest of parameters. -> Sheena\n",
    "3) Those tables that you consider necessary to describe the results obtained for the different network configurations. Explain and reason the results presented in the tables.\n",
    "    - Tables -> Sheena\n",
    "    - Heatmaps -> Bruno\n",
    "    - Best run Train-Validation Accuracy plot -> Sheena\n",
    "4) Your own conclusions with respect the results obtained. -> Bruno"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
